{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b1c34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/home/junho/Workspace/.venv/lib64/python3.13/site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, charset_normalizer, certifi, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.8.3 charset_normalizer-3.4.3 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2d16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head 모델 로드 완료. (Device: cuda)\n",
      "Head 모델 추론 완료. Feature Shape: (1, 256, 56, 56)\n",
      "서버로 Feature 전송 중...\n",
      "\n",
      "서버 응답 성공!\n",
      "  - 최종 예측 결과: {'case_prediction': 1, 'location_prediction': 5}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIG\n",
    "# ==============================================================================\n",
    "HEAD_MODEL_PATH = \"models_split/SP1-head.pt\"\n",
    "TARGET_IMAGE_PATH = \"testimg/case1_5_Color.png\"\n",
    "SERVER_URL = \"http://127.0.0.1:8000/infer_tail\"\n",
    "SPLIT_LAYER_NAME = 'layer1'\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Head 모델 아키텍처 정의\n",
    "# ==============================================================================\n",
    "class InternalHeadModel(nn.Module):\n",
    "    def __init__(self, original_backbone, split_layer_name):\n",
    "        super().__init__()\n",
    "        layers = OrderedDict()\n",
    "        for name, module in original_backbone.named_children():\n",
    "            layers[name] = module\n",
    "            if name == split_layer_name:\n",
    "                break\n",
    "        self.features = nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 메인 실행 로직\n",
    "# ==============================================================================\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # --- 1. Head 모델 로드 ---\n",
    "    original_backbone_for_head = models.resnet50(weights=None).to(device)\n",
    "    head_model = InternalHeadModel(original_backbone_for_head, SPLIT_LAYER_NAME).to(device)\n",
    "    head_model.load_state_dict(torch.load(HEAD_MODEL_PATH, map_location=device))\n",
    "    head_model.eval()\n",
    "    print(f\"Head 모델 로드 완료. (Device: {device})\")\n",
    "\n",
    "    # --- 2. 이미지 로드 및 전처리 ---\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(TARGET_IMAGE_PATH).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # --- 3. Head 모델로 추론하여 중간 피처맵 추출 ---\n",
    "    with torch.no_grad():\n",
    "        feature_tensor = head_model(input_tensor)\n",
    "    \n",
    "    feature_np = feature_tensor.cpu().numpy()\n",
    "    print(f\"Head 모델 추론 완료. Feature Shape: {feature_np.shape}\")\n",
    "\n",
    "    # --- 4. 피처맵을 서버로 전송 ---\n",
    "    packed_feature = feature_np.tobytes()\n",
    "    metadata = {\n",
    "        \"original_shape\": list(feature_np.shape),\n",
    "        \"dtype\": feature_np.dtype.name\n",
    "    }\n",
    "    \n",
    "    files = {\n",
    "        \"file\": (\"feature.bin\", packed_feature, \"application/octet-stream\"),\n",
    "        \"metadata\": (None, json.dumps(metadata), \"application/json\")\n",
    "    }\n",
    "\n",
    "    print(\"서버로 Feature 전송 중...\")\n",
    "    response = requests.post(SERVER_URL, files=files)\n",
    "\n",
    "    # --- 5. 서버로부터 받은 최종 결과 출력 ---\n",
    "    if response.status_code == 200:\n",
    "        print(\"\\n서버 응답 성공!\")\n",
    "        print(f\"  - 최종 예측 결과: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"\\n서버 응답 실패: {response.status_code}\")\n",
    "        print(f\"  - 에러 내용: {response.text}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc69ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
